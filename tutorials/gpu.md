# GPU 存储结构总结

## 概述

GPU 采用**分层存储架构**，不同层级的存储器在**容量、访问速度和作用域**上各有特点。理解这些层次对于编写高性能 GPU 程序至关重要。

---

## GPU 架构与 SM

### 什么是 SM？

**SM (Streaming Multiprocessor)** 是 GPU 的**基本计算单元**，类似于 CPU 的 Core。但 SM 比 CPU Core 更复杂，它内部包含多个执行核心、寄存器文件和片上内存。

### SM 与存储层次的关系

SM 本身**不是存储层次的一层**，而是**包含存储的计算单元**：

```
GPU 架构层级：
┌─────────────────────────────────────────────────────────────┐
│                        GPU Device                           │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              SM (Streaming Multiprocessor)           │    │
│  │  ┌─────────────┐ ┌─────────────┐ ┌───────────────┐  │    │
│  │  │  寄存器文件  │ │  共享内存   │ │   L1 缓存     │  │    │  ← SM 内部存储
│  │  │ (256KB+)   │ │  (48-164KB) │ │ (可配置大小)  │  │    │
│  │  └─────────────┘ └─────────────┘ └───────────────┘  │    │
│  │                                                      │    │
│  │  ┌─────────────────────────────────────────────┐    │    │
│  │  │         执行核心 (CUDA Cores/Tensor Cores)   │    │    │
│  │  └─────────────────────────────────────────────┘    │    │
│  └─────────────────────────────────────────────────────┘    │
│                             ↑                               │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              L2 缓存 (所有 SM 共享)                   │    │
│  └─────────────────────────────────────────────────────┘    │
│                             ↑                               │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              全局内存 (设备 DRAM)                     │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
```

**关键区分**：
- **SM** = 计算单元（类似 CPU Core）
- **SM 内部包含**：寄存器、共享内存、L1 缓存
- **SM 外部共享**：L2 缓存、全局内存

### 存储分布一览

| 存储类型 | 位置 | 是否属于 SM |
|----------|------|-------------|
| **寄存器** | SM 内部 | ✅ 属于 SM |
| **共享内存** | SM 内部 | ✅ 属于 SM |
| **L1 缓存** | SM 内部 | ✅ 属于 SM |
| **L2 缓存** | 设备级别，所有 SM **共享** | ❌ 不属于单个 SM |
| **全局内存** | 设备 DRAM，所有 SM **共享** | ❌ 不属于 SM |

**注意**：不能笼统说"存储属于 SM"，要区分是 SM **内部私有**还是**外部共享**的。

```
SM 边界示意：
┌─────────────────────────────────────────┐
│              SM 内部（私有）              │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐   │
│  │  寄存器  │ │ 共享内存 │ │ L1 缓存 │   │  ← 只属于这个 SM
│  └─────────┘ └─────────┘ └─────────┘   │
│                                         │
│  ┌─────────────────────────────────┐   │
│  │        执行核心 (计算单元)        │   │
│  └─────────────────────────────────┘   │
└─────────────────────────────────────────┘
              ↕ 通过 interconnect 连接
┌─────────────────────────────────────────┐
│           SM 外部（共享）                 │
│  ┌─────────────┐ ┌─────────────────┐   │
│  │   L2 缓存   │ │    全局内存      │   │  ← 所有 SM 共享访问
│  │  (设备级别)  │ │   (设备 DRAM)   │   │
│  └─────────────┘ └─────────────────┘   │
└─────────────────────────────────────────┘
```

---

## 存储层次金字塔

```
        速度 ↑
             │    ┌─────────────┐
        最快 │    │   寄存器     │  ← SM 内部，每个线程私有
             │    ├─────────────┤
             │    │  共享内存    │  ← SM 内部，Block 内共享
             │    ├─────────────┤
             │    │   L1 缓存   │  ← SM 内部缓存
             │    ├─────────────┤
             │    │   L2 缓存   │  ← 所有 SM 共享
             │    ├─────────────┤
             │    │  全局内存   │  ← 所有 SM 共享
        最慢 │    ├─────────────┤
             │    │  主机内存   │  ← 通过 PCIe 访问
             │    └─────────────┘
             └────────────────────→ 容量
```

---

## 各存储类型详解

### 1. 寄存器 (Registers)

| 属性 | 说明 |
|------|------|
| **作用域** | 单个线程私有 |
| **生命周期** | 线程执行期间 |
| **容量** | 每个 SM 有数千个寄存器，每个线程通常可用几十个 |
| **速度** | **最快**，与 SM 核心同频 |
| **用途** | 存储线程局部变量、中间计算结果 |

**注意**：寄存器溢出时会存入**本地内存**（实际在全局内存中），性能大幅下降。

#### CPU vs GPU 寄存器架构差异

**CPU 寄存器**：
- 寄存器是 CPU 核心的**物理组成部分**，与核心固定绑定
- x86-64 每个核心约 16 个通用寄存器
- 线程切换需要**保存/恢复寄存器状态**（上下文切换开销大）

**GPU 寄存器**：
- GPU 有一个**巨大的共享寄存器文件**（每 SM 可达 256KB+），不是核心独占
- 寄存器文件按线程**动态分区**（每个线程分得一小块，如 64-128 个寄存器）
- 线程切换**零开销**——无需数据移动，只需切换寄存器窗口指针

```
CPU 架构:                    GPU 架构:
┌─────────────────┐          ┌─────────────────────────────────────┐
│    CPU Core     │          │              GPU SM                 │
│ ┌─────────────┐ │          │  ┌─────────────────────────────┐    │
│ │  寄存器组    │ │          │  │    巨大寄存器文件 (256KB+)   │    │
│ │ (16个寄存器) │ │          │  │   存储数万线程的寄存器状态    │    │
│ └─────────────┘ │          │  └─────────────────────────────┘    │
│       ↑ 固定绑定  │          │              ↑ 按线程动态分区       │
└─────────────────┘          │  ┌─────┐ ┌─────┐ ┌─────┐            │
                             │  │Core0│ │Core1│ │ ... │            │
                             │  └─────┘ └─────┘ └─────┘            │
                             │    使用时读取对应线程的寄存器窗口      │
                             └─────────────────────────────────────┘
```

**设计哲学差异**：
- **CPU**：线程少，优化单线程延迟，上下文切换代价高
- **GPU**：线程多（数万），用**零开销线程切换**隐藏内存延迟，优化整体吞吐量

---

### 2. 共享内存 (Shared Memory)

| 属性 | 说明 |
|------|------|
| **作用域** | 同 Block 内的所有线程共享 |
| **生命周期** | Block 执行期间 |
| **容量** | 每 SM 通常 48KB-164KB（因架构而异） |
| **速度** | **极快**，约与 L1 缓存同级 |
| **物理位置** | 片上存储 (On-chip SRAM) |

**特点**：
- 可编程的 L1 缓存，程序员显式控制数据的加载和存储
- 用于 Block 内线程间的**数据共享**和**协作计算**
- 需要处理** bank conflict** 以避免性能下降

**分布式共享内存**（Compute Capability 9.0+）：
- Cluster 内的不同 Block 可以相互访问对方的共享内存
- 支持跨 Block 的原子操作

---

### 3. L1 / L2 缓存

#### L1 缓存
- **位置**：每个 SM 独立
- **大小**：可配置（通常与共享内存共享物理存储）
- **作用**：缓存全局内存访问，减少全局内存访问延迟

#### L2 缓存
- **位置**：设备级别，所有 SM 共享
- **大小**：数 MB（如 A100 有 40MB L2）
- **作用**：
  - 缓存全局内存和本地内存访问
  - 支持**持久化缓存**（Persistent Cache），可设置数据优先保留

**L2 持久化访问**（CC 8.0+）：
- 可为频繁访问的数据设置 L2 持久化区域
- 减少重复数据从全局内存的加载

---

### 4. 全局内存 (Global Memory)

| 属性 | 说明 |
|------|------|
| **作用域** | 所有线程、所有 Grid 可访问 |
| **生命周期** | 应用程序生命周期 |
| **容量** | 数 GB 到数十 GB（显存） |
| **速度** | **最慢**，高延迟（数百时钟周期） |
| **物理位置** | 设备 DRAM（显存芯片） |

**访问优化要点**：
- **合并访问**（Coalesced Access）：相邻线程访问相邻内存地址，可合并为一次事务
- **对齐访问**：内存地址按 32/64/128 字节对齐
- 使用 `cudaMallocPitch()` 分配 2D 数组以获得更好对齐

---

### 5. 本地内存 (Local Memory)

| 属性 | 说明 |
|------|------|
| **作用域** | 单个线程私有 |
| **存储位置** | **全局内存中**（不在片上） |
| **用途** | 寄存器溢出、动态索引的局部数组、大结构体 |

**注意**：虽然叫"本地"内存，但实际存储在全局内存中，访问速度很慢。

---

### 6. 常量内存 (Constant Memory)

| 属性 | 说明 |
|------|------|
| **作用域** | 所有线程只读访问 |
| **容量** | 64 KB |
| **特点** | 有专门的常量缓存，广播读取效率高 |
| **用途** | 存储 kernel 中只读的常量数据 |

---

### 7. 纹理/表面内存 (Texture/Surface Memory)

| 属性 | 说明 |
|------|------|
| **特点** | 专门的纹理缓存，支持硬件插值、归一化坐标 |
| **用途** | 图像处理、需要插值的数据访问模式 |
| **趋势** | 现代 CUDA 更推荐使用全局内存 + 普通缓存 |

---

## 存储类型对比表

| 存储类型 | 作用域 | 生命周期 | 速度 | 容量 | 物理位置 |
|----------|--------|----------|------|------|----------|
| 寄存器 | 线程 | 线程 | ⚡⚡⚡⚡⚡ | ~KB | 片上 |
| 共享内存 | Block | Block | ⚡⚡⚡⚡ | ~10-100KB | 片上 |
| L1 缓存 | SM | 动态 | ⚡⚡⚡⚡ | 可配置 | 片上 |
| L2 缓存 | 设备 | 动态 | ⚡⚡⚡ | 数 MB | 片上 |
| 常量内存 | Grid | 应用 | ⚡⚡⚡ | 64 KB | 全局+缓存 |
| 纹理内存 | Grid | 应用 | ⚡⚡⚡ | 受缓存限制 | 全局+缓存 |
| 全局内存 | Grid | 应用 | ⚡ | 数 GB | 片外 DRAM |
| 本地内存 | 线程 | 线程 | ⚡ | 受全局内存限制 | 片外 DRAM |
| 主机内存 | 主机 | 应用 | ⚡（通过 PCIe）| 系统内存 | CPU DRAM |

---

## 关键优化策略

### 1. 减少全局内存访问
- 将数据加载到共享内存，在共享内存中进行多次复用计算
- 使用寄存器存储临时变量

### 2. 合并内存访问
- 确保 warp 内的线程访问连续的内存地址
- 避免分散的内存访问模式

### 3. 避免寄存器溢出
- 控制 kernel 中变量数量
- 减少递归调用和大数组

### 4. 利用 L2 持久化
- 对重复访问的数据设置 L2 持久化窗口
- 提高缓存命中率

### 5. 共享内存 Bank Conflict
- 设计数据结构使线程访问不同 bank
- 使用 `cudaMallocPitch()` 处理 2D 数据

---

## Unified Memory（统一内存）

现代 GPU（Pascal 架构+）支持**Unified Memory**，提供单一虚拟地址空间：

- CPU 和 GPU 使用**同一指针**访问数据
- 数据按需自动在 CPU 和 GPU 之间迁移
- 支持**超量分配**（oversubscription）：分配超过 GPU 显存的内存
- 硬件页面错误和迁移（Pascal+）

**使用场景**：
- 简化代码，减少显式数据传输
- 数据访问模式稀疏或不可预测时
- 需要超量使用 GPU 内存时

